{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_8_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAPXS4UnoI2jTtJUXQxmM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hce2/google_drive/blob/main/chapter_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망\n",
        "- 로지스틱 회귀 (일반 ML 모형) : 81% /1950년대\n",
        "- 인공신경망 (딥러닝 초기 모형) : 87% / 1940-80년대\n",
        "- 합성곱(Convolution, CNN) / 이미지\n",
        "  + 발전사 : alexent (2012) -> resnet -> efficientnet\n",
        "  + 채널, 이미지의 너비, 크기 (파라미터 튜닝)\n",
        "  + Vision Transformer\n",
        "- 비디오\n",
        "  + 객체인식(Object Detection)\n",
        "  + Yolo 논문\n",
        "- RNN / LSTM (자연어 처리)\n",
        "  + 구글 2017년 Transformer (논문)"
      ],
      "metadata": {
        "id": "9LGbSEr1Q0l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱의 장점\n",
        "- 기존 : 1차원 배열에서만 연산이 가능\n",
        "- 2차원 배열에도 연산을 할 수 있도록 구현\n",
        "  + 선형대수를 공부해야 하나요?"
      ],
      "metadata": {
        "id": "fD2q7P_mc32Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IffWrzmXFVCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef4519c-2b4e-4384-f15b-0c868bdecd64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fda5c93dcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 패딩의 목적\n",
        "- 배열의 크기를 조정하더라도 이미지 원 특성이 손실되는 것을 방지하는 것"
      ],
      "metadata": {
        "id": "cSrHrd_WhpXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TeFfm7ph0YZ",
        "outputId": "9b3db182-65b5-4014-d203-b082b7752472"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fda57b10650>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 풀링\n",
        "- 값을 추출\n",
        "\n",
        "\n",
        "100 x 100 이미지 --> (수치로) 주요 이미지의 특성만 뽑은 후, 이미지와 같게 만듬(50 x 50)"
      ],
      "metadata": {
        "id": "AxHdGmuWi8ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "p.437\n",
        "- 1단계 : 이미지 데이터 입력\n",
        "- 2단계 : 합성곱 층\n",
        "  + (1) kernel_size + padding\n",
        "  + (2) 활성화 함수 적용\n",
        "  + (3) 각각의 특성맵을 산출\n",
        "- 3단계 : 풀링층\n",
        "  + (1) Max Pooling : 최댓값 추출\n",
        "  + (2) 최종 특성맵\n",
        "- 위 과정을 계속 반복하는 것이 CNN 알고리즘\n",
        "- 4단계 : 밀집층 (Fully Connected Layer)\n",
        "  + Chapter 7장에서 이미 배움\n",
        "- 5단계 : 분류 예측값을 산출 (Softmax 활성화 함수)\n",
        "\n",
        "주요 키워드 : 전이학습 (Transfer Learning) / 파인 튜닝\n",
        "  + 캐글 경진대회\n",
        "  + 클래스 공부 필수"
      ],
      "metadata": {
        "id": "WOZkPEG2nUCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 합성곱\n",
        "  + 입력 데이터에 유용한 특성만 드러나게 하는 것\n",
        "    + 모델 훈련 : 인공신경망은 가중치와 절편을 랜덤하게 초기화한 다음 에포크를 반복하면서 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최석의 가중치와 절편을 찾는다\n",
        "  + 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형 계산이다. \n",
        "  + 하지만 밀집층과 달리 각 합성곱은 입력 전체가 아니라 일부만 사용하여 선형 계산을 수행한다.\n",
        "  + 뉴런 --> 필터 혹은 커널이라고 부름\n",
        "\n",
        "- 특성 맵\n",
        "  + 합성곱 층이나 풀링 층의 출력 배열\n",
        "  + 필터 하나가 하나의 특성 맵을 만든다. \n",
        "  + 합성곱 층에서 5개의 필터를 적용하면 5개의 특성 맵이 만들어진다.\n",
        " \n",
        "- 패딩\n",
        "  + 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀\n",
        "  + 패딩을 사용하지 않는 것 --> 밸리드 패딩\n",
        "  + 합성곱 층의 출력 크기를 입력과 동일하게 만들기 위해 입력에 패딩을 추가하는 것 --> 세임 패딩\n",
        "\n",
        "- 스트라이드\n",
        "  + 합성곱 층에서 필터가 입력 위를 이동하는 크기\n",
        "  + 일반적으로 1픽셀을 사용\n",
        "\n",
        "- 풀링\n",
        "  + 가중치가 없고 특성 맵의 가로세로 크기를 줄이는 역할\n",
        "  + 대표적으로 최대 풀링과 평균 풀링이 있으며 (2,2) 풀링으로 입력을 절반으로 줄임"
      ],
      "metadata": {
        "id": "l-YYckM9rSfT"
      }
    }
  ]
}